{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# DeepSeek-R1 with SGLang and example applications\n",
    "\n",
    "Throughout this tutorial, you'll leverage AMD GPUs to deploy the powerful language model [DeepSeek-R1-Distill-Qwen-32B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B). The tutorial covers setting up an AI development environment and explores two main practical applications:\n",
    "\n",
    "*  **Advanced chatbot:** Using Open WebUI to create a sophisticated chatbot with web search and file interaction capabilities.\n",
    "*  **Code development assistant:** Installing and utilizing the AI Toolkit Code extension to perform code analysis and pair programming tasks.\n",
    "\n",
    "Let's dive in!\n",
    "\n",
    "**Note**: The same steps can be applied to serve DeepSeek-R1(671B) on a single AMD MI300X node. For more information about running this model, see [this blog post](https://rocm.blogs.amd.com/artificial-intelligence/DeepSeekR1-Part2/README.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launching the SGLang server on AMD GPUs\n",
    "\n",
    "The following runs the `sglang.launch_server` command to initiate the server. Press on the \"+\" new tab button inside this Jupyter server next to the current notebook tab. Then click on \"Terminal\" to start a terminal window. Finally, copy the following SGLang command to create your OpenAI compatible model end-point.\n",
    "\n",
    "**Important**: This command will download the model from Hugging Face repository, then loads the model in your GPU memory. \n",
    "```bash\n",
    "INFERENCE_PORT=30000 \\\n",
    "INFERENCE_MODEL=deepseek-ai/DeepSeek-R1-Distill-Qwen-32B \\\n",
    "API_KEY=\"abc-123\" \\\n",
    "python3 -m sglang.launch_server \\\n",
    "    --model deepseek-ai/DeepSeek-R1-Distill-Qwen-32B \\\n",
    "    --port 30000 \\\n",
    "    --trust-remote-code \\\n",
    "    --disable-radix-cache \\\n",
    "    --host 0.0.0.0 \\\n",
    "    --context-length 4000 \\\n",
    "    --api-key \"abc-123\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait until the model is full loaded and availabe for you. The server should print a message after loading the model indicating the server is ready and the model is fully loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Upon a successful launch, your server should be accepting incoming traffic through an OpenAI-compatible API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to use open-ai compatible calls to our SGLang server, and ensure that we can get a response from our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    base_url=\"http://localhost:30000/v1\",  # must be http not https\n",
    "    api_key=\"abc-123\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"List 3 countries and their capitals.\"},\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=64,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can resume the rest of this tutorial on your own local device. You can use the code provided above to run on your own local device to verify the endpoint is reachable by executing it from your local device using your Server's public IP address. The value of `PORT_NUMBER` was set to `INFERENCE_PORT` when you executed the SGLang server cell. Retrieve the public IP address of your server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl ifconfig.me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Advanced chatbot with OpenWebUI \n",
    "\n",
    "**Note**: The rest of this tutorial is designed to be executed on your own local device.\n",
    "\n",
    "Follow the installation instructions from the [Open WebUI GitHub repository](https://github.com/open-webui/open-webui).\n",
    "\n",
    "After installation, configure your endpoint URL in the Open WebUI client as follows:\n",
    "\n",
    "- Navigate to `Settings` as shown in the image below:\n",
    "\n",
    "  ![OpenWebUI Setup 1](../assets/openwebui1.png)\n",
    "\n",
    "- Select `Connections` from the left tab.\n",
    "  - Enter the `URL` so that it matches this format: `http://YOUR_SERVER_PUBLIC_IP:PORT_NUMBER/v1`.\n",
    "  - Enter the `Key` to match the API key you passed to `sglang.launch_server`.\n",
    "  - Enter the model name (under `Model IDs`) that exactly matches the argument you passed to `sglang.launch_server`. For example, `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B`. \n",
    "  - Click on the `+` button.\n",
    "  - Click on the `Save` button. \n",
    "\n",
    "  ![OpenWebUI Setup 2](../assets/openwebui2.png)\n",
    "\n",
    "\n",
    "## Chatbot testing with DeepSeek-R1\n",
    "\n",
    "Use Open WebUI to interact with your chatbot. Here is an example prompt:\n",
    "\n",
    "```\n",
    "Imagine facing east. Turn 90° left, then 270° right, then 180° left. Which direction are you facing?\n",
    "```\n",
    "\n",
    "Follow up with a request for code visualization:\n",
    "\n",
    "```\n",
    "Can you give me a simple Python code without importing external libraries to visualize this step-by-step with Unicode arrows?\n",
    "```\n",
    "\n",
    "![OpenWebUI Example](../assets/webui_example.gif)\n",
    "\n",
    "\n",
    "## Code development assistant using the VS Code AI Toolkit\n",
    "\n",
    "Follow these steps to install the AI Toolkit for VS Code extension in VS Code:\n",
    "\n",
    "- Open VS Code.\n",
    "- Navigate to **Extensions** (`Ctrl+Shift+X`).\n",
    "- Search for and install **VS Code AI Toolkit**.\n",
    "- Click on `remote inference` as shown in the image below:\n",
    "\n",
    "  ![AI Toolkit Setup 1](../assets/aitoolkit1.png)\n",
    "\n",
    "- Select `Add a custom model`.\n",
    "\n",
    "  ![AI Toolkit Setup 2](../assets/aitoolkit2.png)\n",
    "\n",
    "- Enter the Open AI-compatible URL matching this format: `http://YOUR_SERVER_PUBLIC_IP:PORT_NUMBER/v1/chat/completions`.\n",
    "\n",
    "  ![AI Toolkit Setup 3](../assets/aitoolkit_url.png)\n",
    "\n",
    "- Enter the model name so that it exactly matches the argument passed to `sglang.launch_server`, for example, `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B`.\n",
    "\n",
    "  ![AI Toolkit Setup 4](../assets/aitoolkit3.png)\n",
    "\n",
    "- Press **Enter** to display the model name. \n",
    "\n",
    "  ![AI Toolkit Setup 5](../assets/aitoolkit5.png)\n",
    "\n",
    "- Enter the HTTP header for authorization matching this format `Authorization: Bearer API KEY` exactly as specified, where `API KEY` must match the key you passed to `sglang.launch_server`. If you used the exact same command provided in this tutorial, enter `Authorization: Bearer abc-123`.\n",
    "\n",
    "  ![AI Toolkit Setup 6](../assets/aitoolkit6.png)\n",
    "\n",
    "After you've completed the steps above, your model should be listed under `MY MODELS` on the left. Click your model to start the corresponding playground.\n",
    "\n",
    "  ![AI Toolkit Setup 7](../assets/aitoolkit.png)\n",
    "\n",
    "\n",
    "## Build a snake game \n",
    "\n",
    "In VS Code, make this request:\n",
    "\n",
    "```\n",
    "\"Can you build a classic snake game? Include 'Powered by DeepSeek-R1 on AMD MI300X' in the corner. Use Python.\"\n",
    "```\n",
    "\n",
    "## Optional advanced challenge: Pac-Man\n",
    "Try building a Pac-Man game with a maximum of three prompts.\n",
    "\n",
    "\n",
    "Happy coding! If you encounter issues or have questions, don’t hesitate to ask or raise an issue on our [Github page](https://github.com/ROCm/gpuaidev)!\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
